{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 경로 설정\n",
    "eeg_folder_path = './EEG_test2_csv'\n",
    "\n",
    "# 파일 목록 가져오기\n",
    "file_list = os.listdir(eeg_folder_path)\n",
    "\n",
    "# 전체 데이터를 저장할 리스트\n",
    "data = []\n",
    "\n",
    "# 가장 긴 데이터 길이를 기준으로 zero-padding\n",
    "max_length = 0\n",
    "\n",
    "# 데이터 읽어오기 및 전처리\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(eeg_folder_path, file_name)\n",
    "    df = pd.read_csv(file_path)\n",
    "    channel_data = df.iloc[:, 0].values  # 첫 번째 열의 데이터만 사용\n",
    "    data.append(channel_data)\n",
    "    if len(channel_data) > max_length:\n",
    "        max_length = len(channel_data)\n",
    "\n",
    "# Zero-padding\n",
    "padded_data = pad_sequences(data, maxlen=max_length, padding='post')\n",
    "\n",
    "# 데이터 정규화\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(padded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type: <class 'numpy.ndarray'>\n",
      "(108, 78001)\n",
      "Sample Data:\n",
      "[[0.76928072 0.77643409 0.77903351 ... 0.4722262  0.47287204 0.        ]\n",
      " [0.40940554 0.4020989  0.40253573 ... 0.4722262  0.47287204 0.        ]\n",
      " [0.93878004 0.93195201 0.93625845 ... 0.4722262  0.47287204 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.84144584 0.84324744 0.84380392 ... 0.4722262  0.47287204 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 타입 확인\n",
    "print(\"Data Type:\", type(normalized_data))\n",
    "\n",
    "# 데이터 일부 출력\n",
    "print(normalized_data.shape)\n",
    "print(\"Sample Data:\")\n",
    "print(normalized_data[:5])  # 예시로 처음 5개 데이터 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Conv1D, Flatten, Conv1DTranspose\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "# 가우시안 노이즈 추가\n",
    "def add_gaussian_noise(data, noise_factor):\n",
    "    noise = np.random.normal(loc=0.0, scale=noise_factor, size=data.shape)\n",
    "    noisy_data = data + noise\n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "7/7 [==============================] - 6s 279ms/step - loss: 0.0866\n",
      "Epoch 2/30\n",
      "7/7 [==============================] - 2s 219ms/step - loss: 0.0660\n",
      "Epoch 3/30\n",
      "7/7 [==============================] - 1s 212ms/step - loss: 0.0525\n",
      "Epoch 4/30\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.0470\n",
      "Epoch 5/30\n",
      "7/7 [==============================] - 1s 185ms/step - loss: 0.0322\n",
      "Epoch 6/30\n",
      "7/7 [==============================] - 2s 272ms/step - loss: 0.0201\n",
      "Epoch 7/30\n",
      "7/7 [==============================] - 2s 224ms/step - loss: 0.0131\n",
      "Epoch 8/30\n",
      "7/7 [==============================] - 1s 196ms/step - loss: 0.0092\n",
      "Epoch 9/30\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 0.0072\n",
      "Epoch 10/30\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 0.0062\n",
      "Epoch 11/30\n",
      "7/7 [==============================] - 1s 185ms/step - loss: 0.0064\n",
      "Epoch 12/30\n",
      "7/7 [==============================] - 1s 198ms/step - loss: 0.0061\n",
      "Epoch 13/30\n",
      "7/7 [==============================] - 1s 205ms/step - loss: 0.0054\n",
      "Epoch 14/30\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.0050\n",
      "Epoch 15/30\n",
      "7/7 [==============================] - 1s 200ms/step - loss: 0.0046\n",
      "Epoch 16/30\n",
      "7/7 [==============================] - 1s 200ms/step - loss: 0.0044\n",
      "Epoch 17/30\n",
      "7/7 [==============================] - 1s 203ms/step - loss: 0.0040\n",
      "Epoch 18/30\n",
      "7/7 [==============================] - 2s 232ms/step - loss: 0.0038\n",
      "Epoch 19/30\n",
      "7/7 [==============================] - 2s 234ms/step - loss: 0.0037\n",
      "Epoch 20/30\n",
      "7/7 [==============================] - 1s 200ms/step - loss: 0.0031\n",
      "Epoch 21/30\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.0028\n",
      "Epoch 22/30\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.0025\n",
      "Epoch 23/30\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.0023\n",
      "Epoch 24/30\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 0.0021\n",
      "Epoch 25/30\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.0021\n",
      "Epoch 26/30\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.0019\n",
      "Epoch 27/30\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.0020\n",
      "Epoch 28/30\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.0019\n",
      "Epoch 29/30\n",
      "7/7 [==============================] - 1s 183ms/step - loss: 0.0019\n",
      "Epoch 30/30\n",
      "7/7 [==============================] - 1s 176ms/step - loss: 0.0017\n",
      "4/4 [==============================] - 1s 20ms/step\n",
      "float32\n",
      "(108, 64)\n"
     ]
    }
   ],
   "source": [
    "# Denoising Autoencoder 모델 생성\n",
    "def create_denoising_autoencoder(input_shape, encoding_dim):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    encoded = Flatten()(input_layer)\n",
    "    encoded = Dense(128, activation='relu')(encoded)\n",
    "    encoded = Dense(64, activation='relu')(encoded)\n",
    "    encoded = Dense(32, activation='relu')(encoded)\n",
    "    encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "    # Decoder\n",
    "    decoded = Dense(32, activation='relu')(encoded)\n",
    "    decoded = Dense(64, activation='relu')(decoded)\n",
    "    decoded = Dense(128, activation='relu')(decoded)\n",
    "    decoded = Dense(np.prod(input_shape), activation='sigmoid')(decoded)\n",
    "    decoded = Reshape(input_shape)(decoded)\n",
    "\n",
    "    # Autoencoder\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "    # Encoder\n",
    "    encoder = Model(inputs=input_layer, outputs=encoded)\n",
    "\n",
    "    return autoencoder, encoder\n",
    "\n",
    "# 입력 데이터의 형태\n",
    "input_shape = normalized_data.shape[1:]\n",
    "encoding_dim = 64\n",
    "\n",
    "# 가우시안 노이즈 추가\n",
    "noise_factor = 0.5\n",
    "noisy_data = add_gaussian_noise(normalized_data, noise_factor)\n",
    "\n",
    "# Denoising Autoencoder 모델 생성\n",
    "autoencoder, encoder = create_denoising_autoencoder(input_shape, encoding_dim)\n",
    "\n",
    "# 모델 학습\n",
    "autoencoder.fit(noisy_data, normalized_data, epochs=30, batch_size=16, shuffle=True, verbose=1)\n",
    "\n",
    "# 특징 추출 (인코더의 출력)\n",
    "eeg_test_features = encoder.predict(normalized_data)\n",
    "print(eeg_test_features.dtype) # float32\n",
    "print(eeg_test_features.shape) # (108, 64) 이어야 함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "        39.582573 ],\n",
       "       [ 0.       ,  0.       ,  0.       , ...,  0.       ,  1.9774508,\n",
       "        13.7914915],\n",
       "       [ 2.7080767,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "        54.24855  ],\n",
       "       ...,\n",
       "       [ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "         7.134301 ],\n",
       "       [ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "        47.751797 ],\n",
       "       [ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
       "        41.317375 ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded_eeg = pd.DataFrame(eeg_test_features)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_file = \"eeg_test_features.csv\"\n",
    "df_encoded_eeg.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
